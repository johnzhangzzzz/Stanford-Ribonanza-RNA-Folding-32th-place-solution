{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import pandas as pd\n","import os, gc\n","import numpy as np\n","from sklearn.model_selection import KFold\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.cuda.amp import GradScaler, autocast\n","\n","import neptune\n","from neptune.utils import stringify_unsupported\n","from tqdm import tqdm, notebook\n","import transformers\n","from collections import defaultdict\n","import glob"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import sys\n","import argparse\n","from copy import copy\n","import importlib"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["BASEDIR= './'\n","for DIRNAME in 'configs data models postprocess metrics utils repos debug_jupyternb'.split():\n","    sys.path.append(f'{BASEDIR}/{DIRNAME}/')\n","#添加所需模块路径至sys.path"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#定义命令行参数\n","parser = argparse.ArgumentParser(description=\"\")\n","parser.add_argument(\"-C\", \"--config\", help=\"config filename\", default=\"cfg_0\")\n","parser.add_argument(\"-G\", \"--gpu_id\", default=\"\", help=\"GPU ID\")\n","parser_args, other_args = parser.parse_known_args(sys.argv)\n","#cfg = copy(importlib.import_module(parser_args.config).cfg)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["Namespace(config='cfg_0', gpu_id='')"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["parser_args"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["if parser_args.gpu_id != \"\":\n","    os.environ['CUDA_VISIBLE_DEVICES'] = str(parser_args.gpu_id)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["#命令行中重写或者添加额外cfg的参数\n","# overwrite params in config with additional arg\n","# oo=['d','--aa',3]\n","# {k.replace('-',''):v for k, v in zip(oo[1::2], oo[2::2])}   \n","if len(other_args) > 1:\n","    other_args = {k.replace('-',''):v for k, v in zip(other_args[1::2], other_args[2::2])}\n","\n","    for key in other_args:\n","        if key in cfg.__dict__:\n","\n","            print(f'overwriting cfg.{key}: {cfg.__dict__[key]} -> {other_args[key]}')\n","            cfg_type = type(cfg.__dict__[key])\n","            if cfg_type == bool:\n","                cfg.__dict__[key] = other_args[key] == 'True'\n","            elif cfg_type == type(None):\n","                cfg.__dict__[key] = other_args[key]\n","            else:\n","                cfg.__dict__[key] = cfg_type(other_args[key])"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["cfg = copy(importlib.import_module('cfg_0').cfg)#复制namespace"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["'# start naptun\\nfns = [parser_args.config] + [getattr(cfg, s) for s in \\'dataset model\\'.split()]#获取文件名\\nfns = sum([glob.glob(f\"{BASEDIR }/*/{fn}.py\") for fn in  fns], [])#获取文件的相对路径'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["'''# start naptun\n","fns = [parser_args.config] + [getattr(cfg, s) for s in 'dataset model'.split()]#获取文件名\n","fns = sum([glob.glob(f\"{BASEDIR }/*/{fn}.py\") for fn in  fns], [])#获取文件的相对路径'''"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["['cfg_0', 'ds_1', 'transfomer_block']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["fns = [parser_args.config] + [getattr(cfg, s) for s in 'dataset model '.split()]\n","fns"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["['./configs/cfg_0.py', './data/ds_1.py', './models/transfomer_block.py']"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["fns = sum([glob.glob(f\"{BASEDIR }/*/{fn}.py\") for fn in  fns], [])\n","fns"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["#设置neptune_api_token，用于将数据上传至Neptune云端，默认上传项目为官方提供的公有项目\n","if cfg.neptune_project == \"common/quickstarts\":\n","    neptune_api_token=neptune.ANONYMOUS_API_TOKEN\n","else:\n","    neptune_api_token=cfg.neptune_api_token\n","    #此分支将数据上传至你的私有项目"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_24317/3572702261.py:2: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n","  neptune_run = neptune.init_run(\n"]},{"name":"stdout","output_type":"stream","text":["https://app.neptune.ai/common/quickstarts/e/QUI-99334\n"]}],"source":["#初始化neptune.init_run\n","neptune_run = neptune.init_run(\n","        project=cfg.neptune_project,\n","        tags=\"demo_0\",\n","        mode=\"async\",\n","        api_token=neptune_api_token,\n","        capture_stdout=False,\n","        capture_stderr=False,\n","        source_files=fns #需要跟踪的源文件位置\n","    )\n","\n","#print(f\"Neptune system id : {neptune_run._sys_id}\")\n","#print(f\"Neptune URL       : {neptune_run.get_url()}\")\n","neptune_run[\"cfg\"] = stringify_unsupported(cfg.__dict__)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sequence_id</th>\n","      <th>sequence</th>\n","      <th>experiment_type</th>\n","      <th>dataset_name</th>\n","      <th>reads</th>\n","      <th>signal_to_noise</th>\n","      <th>SN_filter</th>\n","      <th>reactivity_0001</th>\n","      <th>reactivity_0002</th>\n","      <th>reactivity_0003</th>\n","      <th>...</th>\n","      <th>reactivity_error_0197</th>\n","      <th>reactivity_error_0198</th>\n","      <th>reactivity_error_0199</th>\n","      <th>reactivity_error_0200</th>\n","      <th>reactivity_error_0201</th>\n","      <th>reactivity_error_0202</th>\n","      <th>reactivity_error_0203</th>\n","      <th>reactivity_error_0204</th>\n","      <th>reactivity_error_0205</th>\n","      <th>reactivity_error_0206</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>8cdfeef009ea</td>\n","      <td>GGGAACGACUCGAGUAGAGUCGAAAAACGUUGAUAUGGAUUUACUC...</td>\n","      <td>2A3_MaP</td>\n","      <td>15k_2A3</td>\n","      <td>2343</td>\n","      <td>0.944</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>51e61fbde94d</td>\n","      <td>GGGAACGACUCGAGUAGAGUCGAAAAACAUUGAUAUGGAUUUACUC...</td>\n","      <td>2A3_MaP</td>\n","      <td>15k_2A3</td>\n","      <td>5326</td>\n","      <td>1.933</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25ce8d5109cd</td>\n","      <td>GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUC...</td>\n","      <td>2A3_MaP</td>\n","      <td>15k_2A3</td>\n","      <td>4647</td>\n","      <td>2.347</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>07dcfb6d1965</td>\n","      <td>GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUC...</td>\n","      <td>2A3_MaP</td>\n","      <td>15k_2A3</td>\n","      <td>102843</td>\n","      <td>11.824</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>e561cc042a4c</td>\n","      <td>GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUC...</td>\n","      <td>2A3_MaP</td>\n","      <td>15k_2A3</td>\n","      <td>7665</td>\n","      <td>3.519</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 419 columns</p>\n","</div>"],"text/plain":["    sequence_id                                           sequence  \\\n","0  8cdfeef009ea  GGGAACGACUCGAGUAGAGUCGAAAAACGUUGAUAUGGAUUUACUC...   \n","1  51e61fbde94d  GGGAACGACUCGAGUAGAGUCGAAAAACAUUGAUAUGGAUUUACUC...   \n","2  25ce8d5109cd  GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUC...   \n","3  07dcfb6d1965  GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUC...   \n","4  e561cc042a4c  GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUC...   \n","\n","  experiment_type dataset_name   reads  signal_to_noise  SN_filter  \\\n","0         2A3_MaP      15k_2A3    2343            0.944          0   \n","1         2A3_MaP      15k_2A3    5326            1.933          1   \n","2         2A3_MaP      15k_2A3    4647            2.347          1   \n","3         2A3_MaP      15k_2A3  102843           11.824          1   \n","4         2A3_MaP      15k_2A3    7665            3.519          1   \n","\n","   reactivity_0001  reactivity_0002  reactivity_0003  ...  \\\n","0              NaN              NaN              NaN  ...   \n","1              NaN              NaN              NaN  ...   \n","2              NaN              NaN              NaN  ...   \n","3              NaN              NaN              NaN  ...   \n","4              NaN              NaN              NaN  ...   \n","\n","   reactivity_error_0197  reactivity_error_0198  reactivity_error_0199  \\\n","0                    NaN                    NaN                    NaN   \n","1                    NaN                    NaN                    NaN   \n","2                    NaN                    NaN                    NaN   \n","3                    NaN                    NaN                    NaN   \n","4                    NaN                    NaN                    NaN   \n","\n","   reactivity_error_0200  reactivity_error_0201  reactivity_error_0202  \\\n","0                    NaN                    NaN                    NaN   \n","1                    NaN                    NaN                    NaN   \n","2                    NaN                    NaN                    NaN   \n","3                    NaN                    NaN                    NaN   \n","4                    NaN                    NaN                    NaN   \n","\n","   reactivity_error_0203  reactivity_error_0204  reactivity_error_0205  \\\n","0                    NaN                    NaN                    NaN   \n","1                    NaN                    NaN                    NaN   \n","2                    NaN                    NaN                    NaN   \n","3                    NaN                    NaN                    NaN   \n","4                    NaN                    NaN                    NaN   \n","\n","   reactivity_error_0206  \n","0                    NaN  \n","1                    NaN  \n","2                    NaN  \n","3                    NaN  \n","4                    NaN  \n","\n","[5 rows x 419 columns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_parquet(cfg.train_df) #载入原始数据\n","df.head()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["BPPs_RNA_Dataset = importlib.import_module(cfg.dataset).BPPs_RNA_Dataset \n","#根据rna预测数据定制的pre-loaded dataset，继承自torch.utils.data.Dataset\n","LenMatchBatchSampler = importlib.import_module(cfg.dataset).LenMatchBatchSampler #加入mask长度匹配的BatchSampler\n","DeviceDataLoader = importlib.import_module(cfg.dataset).DeviceDataLoader #将数据包装成迭代器\n","Squeezeformer_RNA = importlib.import_module(cfg.model).Squeezeformer_RNA #载入模型\n","loss_f = importlib.import_module(cfg.loss).loss #载入损失函数\n","MAE=importlib.import_module(cfg.metrics).MAE #载入评价函数\n","OUT=cfg.OUT\n","SEED=cfg.SEED\n","nfolds=cfg.nfolds\n","fold=cfg.fold\n","set_seed=importlib.import_module(cfg.utils).set_seed"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["set_seed(SEED)\n","os.makedirs(OUT, exist_ok=True)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["'./'"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["OUT"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["ds_train = BPPs_RNA_Dataset(df, mode='train', fold=fold, nfolds = nfolds)\n","ds_train_len = BPPs_RNA_Dataset(df, mode='train', fold=fold, \n","            nfolds=nfolds, mask_only=True)\n","sampler_train = torch.utils.data.RandomSampler(ds_train_len)\n","len_sampler_train = LenMatchBatchSampler(sampler_train, batch_size=cfg.bs,\n","            drop_last=True)\n","dl_train = DeviceDataLoader(torch.utils.data.DataLoader(ds_train,\n","                                                        batch_sampler=len_sampler_train,\n","                                                        num_workers=cfg.num_workers,\n","                                                        persistent_workers=True),\n","                                                        cfg.device)\n","###torch.utils.data.DataLoader：Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n","###对未进行DeviceDataLoader类进行包装的ds_train使用iter()方法后，属性变成MultiProcessingDataLoaderIter，主要原因ds_train是返回对象为两个{}，\n","###所以通过使用DeviceDataLoader，类进行包装可以让两个{}变为一个\n","\n","ds_val = BPPs_RNA_Dataset(df, mode='eval', fold=fold, nfolds=nfolds)\n","ds_val_len = BPPs_RNA_Dataset(df, mode='eval', fold=fold, nfolds=nfolds, \n","            mask_only=True)\n","sampler_val = torch.utils.data.SequentialSampler(ds_val_len)\n","len_sampler_val = LenMatchBatchSampler(sampler_val, batch_size=cfg.bs, \n","            drop_last=False)\n","dl_val= DeviceDataLoader(torch.utils.data.DataLoader(ds_val, \n","            batch_sampler=len_sampler_val, num_workers=cfg.num_workers), cfg.device)\n","\n","if not os.path.exists(f\"{cfg.output_dir}/fold{fold}/\"): \n","    os.makedirs(f\"{cfg.output_dir}/fold{fold}/\")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["model = Squeezeformer_RNA(cfg).to(cfg.device)\n","\n","total_steps = len(ds_train)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n","scheduler = transformers.get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=cfg.warmup * (total_steps // cfg.bs),\n","            num_training_steps=cfg.epochs * (total_steps // cfg.bs),\n","            num_cycles=0.5\n","        ) #设置学习率变化函数\n","scaler = GradScaler() #实例化梯度缩放类，用于防止梯度爆炸"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["import warnings \n","warnings.filterwarnings(\"ignore\")\n","#由于使用了混合精度，"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Train epoch 0: 100%|██████████| 425/425 [00:57<00:00,  7.35it/s]\n","Val epoch 0: 100%|██████████| 140/140 [00:16<00:00,  8.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["val_score: 0.561\n"]},{"name":"stderr","output_type":"stream","text":["Train epoch 1: 100%|██████████| 425/425 [00:57<00:00,  7.36it/s]\n","Val epoch 1: 100%|██████████| 140/140 [00:16<00:00,  8.46it/s]"]},{"name":"stdout","output_type":"stream","text":["val_score: 0.527\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Start the training and validation loop\n","cfg.curr_step = 0 #\n","optimizer.zero_grad()\n","total_grad_norm = None    \n","total_grad_norm_after_clip = None\n","i = 0 \n","\n","L_dl_train = len(dl_train)\n","L_dl_val = len(dl_val)\n","if cfg.debug:\n","    L_dl_train = L_dl_train//cfg.debug_fact\n","    L_dl_val = L_dl_val//cfg.debug_fact\n","    \n","for epoch in range(cfg.epochs):\n","    cfg.curr_epoch = epoch\n","    progress_bar = tqdm(range(L_dl_train)[:], desc=f'Train epoch {epoch}')\n","    tr_it = iter(dl_train)\n","    losses = []\n","    gc.collect()\n","    \n","    model.train()\n","    for itr in progress_bar:\n","        i += 1\n","        cfg.curr_step += cfg.bs\n","        data = next(tr_it)\n","        torch.set_grad_enabled(True)\n","        batch=data\n","        if cfg.mixed_precision:\n","            with autocast():\n","                output_dict = model(batch)\n","        else:\n","            output_dict = model(batch)\n","        loss = output_dict[\"loss\"]\n","        losses.append(loss.item())\n","\n","        if cfg.grad_accumulation >1: \n","            loss /= cfg.grad_accumulation\n","        #有时候内存不够，batchsize太小的时候，用这种方法等效的增大batchsize\n","\n","         #以下为利用梯度混合训练设置，原理详见   \n","         #https://zhuanlan.zhihu.com/p/165152789 和 https://pytorch.org/docs/stable/amp.html\n","            \n","        if cfg.mixed_precision:\n","            scaler.scale(loss).backward()\n","\n","            if i % cfg.grad_accumulation == 0:\n","                if (cfg.track_grad_norm) or (cfg.clip_grad > 0): #吴恩达的视频中有介绍，梯度归一&梯度裁剪 防止梯度爆炸的技术\n","                    scaler.unscale_(optimizer)                          \n","                if cfg.clip_grad > 0:\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.clip_grad)\n","                scaler.step(optimizer)\n","                scaler.update()\n","                optimizer.zero_grad()\n","        else:\n","            loss.backward()\n","            if i % cfg.grad_accumulation == 0:\n","                if cfg.clip_grad > 0:\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.clip_grad)\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","        if scheduler is not None:\n","            scheduler.step()\n","\n","        loss_names = [key for key in output_dict if 'loss' in key]\n","        for l in loss_names:\n","            neptune_run[f\"train/{l}\"].log(value=output_dict[l].item(), step=cfg.curr_step)\n","\n","        neptune_run[\"lr\"].log(\n","                value=optimizer.param_groups[0][\"lr\"], step=cfg.curr_step\n","            )\n","        if total_grad_norm is not None:\n","            neptune_run[\"total_grad_norm\"].log(value=total_grad_norm.item(), step=cfg.curr_step)\n","            neptune_run[\"total_grad_norm_after_clip\"].log(value=total_grad_norm_after_clip.item(), step=cfg.curr_step)           \n","\n","    #if (epoch + 1) % cfg.eval_epochs == 0 or (epoch + 1) == cfg.epochs: \n","    if 1>0:           \n","        model.eval()\n","        torch.set_grad_enabled(False)#also,torch.inference_mode()\n","        val_data = defaultdict(list) #若字典检索不到key，不会报错而回返回一个空的list\n","        val_score = 0 #本次任务的评价函数与损失函数均为MAE，所以没有额外定义metrics\n","\n","        progress_bar = tqdm(range(L_dl_val)[:], desc=f'Val epoch {epoch}')\n","        tr_it = iter(dl_val)\n","        \n","        #for ind_, data in enumerate(tqdm(dl_val, desc=f'Val epoch {epoch}')):\n","            #batch = batch_to_device(data, cfg.device)\n","            #batch = data\n","        \n","        for itr in progress_bar:\n","            data = next(tr_it)\n","            batch=data\n","        \n","            if cfg.mixed_precision:\n","                with autocast():\n","                    output_dict_val = model(batch)\n","            else:\n","                output_dict_val = model(batch)\n","                #单个batch的输出\n","            #常规的计算输出\n","            for key, val in output_dict_val.items():\n","                val_data[key] += [output_dict_val[key]]\n","        for key, val in output_dict_val.items():\n","            value = val_data[key]\n","            if isinstance(value[0], list):\n","                val_data[key] = [item for sublist in value for item in sublist]\n","            else:\n","                if len(value[0].shape) == 0:\n","                    val_data[key] = torch.stack(value)\n","                else:\n","                    val_data[key] = torch.cat(value, dim=0) \n","        #平铺每个batch的输出,并累计所有的batch，用于计算metrics\n","        #val_data['fc_outputs'].shape=torch.Size([45082, 206, 2])，val_data['loss'].shape=torch.Size([1409])，   \n","        if cfg.save_val_data:\n","            torch.save(val_data, f\"{cfg.output_dir}/fold{fold}/val_data_seed{SEED}.csv\")\n","\n","         \n","\n","        #val_df = val_dataloader.dataset.df\n","            \n","        #pp_out = post_process_pipeline(cfg, val_data, val_df)\n","\n","        #val_score = calc_metric(cfg, pp_out, val_df, \"val\")\n","        loss_names_val = [key for key in output_dict_val if 'loss' in key]\n","        loss_names_val += [key for key in output_dict_val if 'score' in key]       \n","        \n","        val_score =val_data['loss'].mean()\n","        if type(val_score)!=dict:\n","            val_score = {f'score':val_score}\n","\n","                   \n","        \n","        for k, v in val_score.items():\n","            print(f\"val_{k}: {v:.3f}\")\n","            if neptune_run:\n","                neptune_run[f\"val/{k}\"].log(v, step=epoch)       \n","    \n","    if not cfg.save_only_last_ckpt:\n","        torch.save({\"model\": model.state_dict()}, f\"{cfg.output_dir}/fold{fold}/checkpoint_last_seed{cfg.SEED}.pth\")    \n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Checkpoint save : datamount/weights/cfg_0/fold0/checkpoint_last_seed2023.pth\n"]}],"source":["torch.save({\"model\": model.state_dict()}, f\"{cfg.output_dir}/fold{fold}/checkpoint_last_seed{cfg.SEED}.pth\")\n","print(f\"Checkpoint save : \" +  f\"{cfg.output_dir}/fold{fold}/checkpoint_last_seed{cfg.SEED}.pth\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shutting down background jobs, please wait a moment...\n","Done!\n","Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n","All 1 operations synced, thanks for waiting!\n","Explore the metadata in the Neptune app:\n","https://app.neptune.ai/common/quickstarts/e/QUI-99334/metadata\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["run_id = neptune_run[\"sys/id\"].fetch()\n","neptune_run.stop()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":2}
